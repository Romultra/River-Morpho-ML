"""
plot_score.py

Load the CSV with test metrics for all epochs and:
  - print the best epoch for several metrics (F1, CSI, loss, precision, recall, accuracy)
  - save plots of loss vs epoch and F1/CSI vs epoch.

By default, the script:
  - reads the metrics CSV path from `eval_cfg.scores_csv`
  - saves plots into `data_cfg.plots_dir`
  - uses `model_cfg.architecture` to label plots and filenames.

The CSV is expected to be generated by `eval_all_checkpoints.py` and to contain
(at least) the following columns:
    epoch, test_loss, test_acc, test_prec, test_rec, test_f1, test_csi

Usage example (from repo root)
------------------------------
    conda activate braided

    # Assuming eval_all_checkpoints.py has already written eval_cfg.scores_csv
    python -m transformer_cnn_model.plot_score

Outputs
-------
  - Console printout of:
        * best epoch by test_f1
        * best epoch by test_csi
        * best epoch by lowest test_loss
        * best epoch by test_prec
        * best epoch by test_rec
        * best epoch by test_acc

  - CSV summary of best epochs:
        data_cfg.plots_dir / "best_epoch_summary.csv"

  - Plots:
        data_cfg.plots_dir / f"test_loss_{model_cfg.architecture}.png"
        data_cfg.plots_dir / f"test_f1_csi_{model_cfg.architecture}.png"
"""

import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from transformer_cnn_model.config import data_cfg, eval_cfg, model_cfg

# Path to CSV with metrics for all epochs (from config)
csv_path = eval_cfg.scores_csv

# Directory where plots will be saved (from config)
plots_dir = data_cfg.plots_dir
plots_dir.mkdir(parents=True, exist_ok=True)

# Nice to have: architecture name for titles / filenames
arch_name = model_cfg.architecture  # e.g. "transunet" or "unet3d"

# Load metrics
df = pd.read_csv(csv_path)

# --------------------------------------------------------------------
# Helper function to print best row for any metric
# --------------------------------------------------------------------
def print_best(df, metric, higher_is_better=True):
    if higher_is_better:
        idx = df[metric].idxmax()
    else:
        idx = df[metric].idxmin()

    row = df.loc[idx]
    print(
        f"Best {metric} : epoch {int(row['epoch'])} "
        f"({metric} = {row[metric]:.6f}, "
        f"loss = {row['test_loss']:.6f}, "
        f"F1 = {row['test_f1']:.4f}, "
        f"CSI = {row['test_csi']:.4f}, "
        f"prec = {row['test_prec']:.4f}, "
        f"rec = {row['test_rec']:.4f}, "
        f"acc = {row['test_acc']:.4f})"
    )
    return row


print("\n==================== BEST EPOCHS ====================")

# Highest F1
best_f1 = print_best(df, "test_f1")

# Highest CSI
best_csi = print_best(df, "test_csi")

# Lowest loss
best_loss = print_best(df, "test_loss", higher_is_better=False)

# Highest precision
best_prec = print_best(df, "test_prec")

# Highest recall
best_rec = print_best(df, "test_rec")

# Highest accuracy
best_acc = print_best(df, "test_acc")

print("=====================================================\n")

# Optional summary table
summary_df = pd.DataFrame({
    "metric": ["F1", "CSI", "Loss", "Precision", "Recall", "Accuracy"],
    "epoch": [
        int(best_f1["epoch"]),
        int(best_csi["epoch"]),
        int(best_loss["epoch"]),
        int(best_prec["epoch"]),
        int(best_rec["epoch"]),
        int(best_acc["epoch"]),
    ],
    "value": [
        best_f1["test_f1"],
        best_csi["test_csi"],
        best_loss["test_loss"],
        best_prec["test_prec"],
        best_rec["test_rec"],
        best_acc["test_acc"],
    ]
})
summary_path = plots_dir / f"best_epoch_summary_{arch_name}.csv"
summary_df.to_csv(summary_path, index=False)
print(f"Saved summary of best epochs to {summary_path}")

# --------------------------------------------------------------------
# Plot test loss vs epoch
# --------------------------------------------------------------------
fig_loss = plt.figure()
plt.plot(df["epoch"], df["test_loss"], marker="o")
plt.xlabel("Epoch")
plt.ylabel("Test loss")
plt.title(f"Test loss vs Epoch ({arch_name})")
plt.grid(True)

loss_plot_path = plots_dir / f"test_loss_{arch_name}.png"
fig_loss.savefig(loss_plot_path, dpi=300, bbox_inches="tight")
print(f"Saved loss plot to {loss_plot_path}")

# --------------------------------------------------------------------
# Plot F1 and CSI vs epoch
# --------------------------------------------------------------------
fig_scores = plt.figure()
plt.plot(df["epoch"], df["test_f1"], marker="o", label="F1")
plt.plot(df["epoch"], df["test_csi"], marker="o", label="CSI")
plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title(f"F1 and CSI vs Epoch ({arch_name})")
plt.legend()
plt.grid(True)

scores_plot_path = plots_dir / f"test_f1_csi_{arch_name}.png"
fig_scores.savefig(scores_plot_path, dpi=300, bbox_inches="tight")
print(f"Saved F1/CSI plot to {scores_plot_path}")

plt.show()
